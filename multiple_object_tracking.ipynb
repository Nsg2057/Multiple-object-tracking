{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1: Understand the problem and setup environment**\n",
        "\n",
        "We're trying to track the trajectory of the ball object across the video. Here we need to detect the ball object first and keep track of that object across the video. \n",
        "\n",
        "\n",
        "**kalman Filter -** \n",
        "\n",
        "Kalman Filter is useful to predict the state of an object and track the object with the given measurements when there is noise included in the measurements.\n",
        "It uses the prior knowledge of the state of the object \n",
        "Kalman Filter uses following equations - \n",
        "The process noise is used to model the uncertainty\n",
        "**Covariance Equation**- uncertainity in the prediction is modeled using this equation \n",
        "**Prediction equation** - predicts the next system state based on the knowledge of the current state\n",
        "**State Update Equation** -  is responsible for the system's current state estimation using the State Update equation\n",
        "**Covariance update equation** - The state update process calculates the Kalman Gain and outputs Current System State Estimate and Current State Estimate Uncertainty, which will input the predicted process\n",
        "**Kalman Gain** - computes a Kalman Gain for each new measurement to minimize the estimate variance \n",
        "\n",
        " \n",
        " Kalman filter process has 2 steps - \n",
        " Start with initialization, and this step is performed only once for the first measurement. Once initialized, the Kalman Filter will predict the system state at the next time step, and it also provides the uncertainty of the prediction\n",
        "1.**Prediction step** -  the Kalman Filter predicts the next state of the system given the previous measurements.\n",
        "Prediction step uses - State Transision Matrix and Control input matrix \n",
        "2.**Updation step**  - the Kalman Filter estimates the current state of the system given the measurement at that time step - uses Measurement Mapping Matrix and the predicted matrix is used to calculate the kalman Gain and update the state of the object. \n",
        "\n",
        "**Single Object tracking** - In this challenge, we're trying to track the single instance of a ball with occlusions. We can track the ball across different frames of the video by using a simple object detector but that fails when the ball goes behind the paper. \n",
        "We need to keep track of the location of the ball even when there is an occlusion. This can be done by using kalman filter. \n",
        "KF object is initialized with random values and gets updated after the first cycle. Then it keeps tracking the centers of the detected object.\n",
        "\n",
        "\n",
        "**Multiple Object tracking** - In this challenge, we're trying to keep track of 2 ball objects in the same video. The challenge in this is to keep track of the trajectory of the each separately even after they cross paths with each other or even collide with each other and change directions. \n",
        "In this case Kalman filter can be used to keep track of the trajectories of each ball instances separately. \n",
        "Need to assign unique identity for 2 trackers to track each detected object separately. and use the kalman function's predict and update to keep track of the detected objects."
      ],
      "metadata": {
        "id": "tYeiKlMbPyOm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_abxKvCzEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fxm6X8NTTBqw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b5ddd38-e51f-441a-ade0-afa4e6c5d460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.2.0\n",
            "  Downloading tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2 MB 4.4 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 33.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
            "\u001b[K     |████████████████████████████████| 454 kB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.46.1)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.17.3)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.7)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, h5py, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n",
            "Collecting keras==2.2.4\n",
            "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
            "\u001b[K     |████████████████████████████████| 312 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Installing collected packages: keras-applications, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "Successfully installed keras-2.2.4 keras-applications-1.0.8\n",
            "Collecting imageai\n",
            "  Downloading imageai-2.1.6-py3-none-any.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.3.2\n",
            "  Downloading matplotlib-3.3.2-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 23.3 MB/s \n",
            "\u001b[?25hCollecting numpy==1.19.3\n",
            "  Downloading numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 33.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from imageai) (2.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imageai) (4.1.2.30)\n",
            "Collecting keras-resnet==0.2.0\n",
            "  Downloading keras-resnet-0.2.0.tar.gz (9.3 kB)\n",
            "Collecting pillow==7.0.0\n",
            "  Downloading Pillow-7.0.0-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 37.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from imageai) (1.4.1)\n",
            "Collecting keras==2.4.3\n",
            "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->imageai) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3->imageai) (3.13)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2021.10.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.3.2->imageai) (4.2.0)\n",
            "Building wheels for collected packages: keras-resnet\n",
            "  Building wheel for keras-resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-resnet: filename=keras_resnet-0.2.0-py2.py3-none-any.whl size=20486 sha256=3bee456b9cee569add19a73d1586645195ead9b7cd55b43ae37729b330fdced7\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/ef/06/5d65f696360436c3a423020c4b7fd8c558c09ef264a0e6c575\n",
            "Successfully built keras-resnet\n",
            "Installing collected packages: numpy, pillow, keras, matplotlib, keras-resnet, imageai\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 7.0.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed imageai-2.1.6 keras-2.4.3 keras-resnet-0.2.0 matplotlib-3.3.2 numpy-1.19.3 pillow-7.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip3 install tensorflow==2.2.0\n",
        "!pip3 install keras==2.2.4\n",
        "!pip3 install imageai --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWZvFv2eLb5C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow.keras\n",
        "from imageai.Detection import ObjectDetection\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mHGng50KKmr"
      },
      "outputs": [],
      "source": [
        "class KalmanFilter(object):\n",
        "    def __init__(self, dt, a_x,a_y, std_acc, x_std_meas, y_std_meas):\n",
        "        # Define sampling time\n",
        "        self.dt = dt\n",
        "        # Define the  control input variables\n",
        "        self.u = np.matrix([[a_x],[a_y]])\n",
        "        # Intial State\n",
        "        self.x = np.matrix([[0], [0], [0], [0]])\n",
        "        # Define the State Transition Matrix A\n",
        "        self.A = np.matrix([[1, 0, self.dt, 0],\n",
        "                            [0, 1, 0, self.dt],\n",
        "                            [0, 0, 1, 0],\n",
        "                            [0, 0, 0, 1]])\n",
        "        # Define the Control Input Matrix B\n",
        "        self.B = np.matrix([[(self.dt**2)/2, 0],\n",
        "                            [0, (self.dt**2)/2],\n",
        "                            [self.dt,0],\n",
        "                            [0,self.dt]])\n",
        "        # Define Measurement Mapping Matrix\n",
        "        self.H = np.matrix([[1, 0, 0, 0],\n",
        "                            [0, 1, 0, 0]])\n",
        "        #Initial Process Noise Covariance\n",
        "        self.Q = np.matrix([[(self.dt**4)/4, 0, (self.dt**3)/2, 0],\n",
        "                            [0, (self.dt**4)/4, 0, (self.dt**3)/2],\n",
        "                            [(self.dt**3)/2, 0, self.dt**2, 0],\n",
        "                            [0, (self.dt**3)/2, 0, self.dt**2]]) * std_acc**2\n",
        "        #Initial Measurement Noise Covariance\n",
        "        self.R = np.matrix([[x_std_meas**2,0],\n",
        "                           [0, y_std_meas**2]])\n",
        "        #Initial Covariance Matrix\n",
        "        self.P = np.eye(self.A.shape[1])\n",
        "    def predict_next_position(self):\n",
        "        #State Transition Matrix and Control input matrix is used to predict the next state of the object\n",
        "        self.x = np.dot(self.A, self.x) + np.dot(self.B, self.u)\n",
        "        self.P = np.dot(np.dot(self.A, self.P), self.A.T) + self.Q\n",
        "        return self.x[0:2]\n",
        "    def update_object_position(self, z):\n",
        "        #Update the state of the object using Measurement Mapping Matrix and Predicted position from the predict function\n",
        "        S = np.dot(self.H, np.dot(self.P, self.H.T)) + self.R\n",
        "        K = np.dot(np.dot(self.P, self.H.T), np.linalg.inv(S))  \n",
        "        self.x = np.round(self.x + np.dot(K, (z - np.dot(self.H, self.x))))   \n",
        "        I = np.eye(self.H.shape[1])\n",
        "        # Update error covariance matrix\n",
        "        self.P = (I - (K * self.H)) * self.P   \n",
        "        return self.x[0:2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vq2oVHfeaU-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2 - In this part we're detecting the ball object from each frame of the video. Here we are using YOLOV3 as object detection model. This model has been trained to detect objects using COCO dataset. This detects the ball object with class = \"sports ball\"."
      ],
      "metadata": {
        "id": "EE7v5FLzxqXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This method detects the ball object in the image provided, calculates the centroid of the object and returns the centroid of the detected object\n",
        "def object_detection(image):\n",
        "  current_directory = os.getcwd()\n",
        "  detector = ObjectDetection() #Initializing the detector object  \n",
        "  detector.setModelTypeAsYOLOv3() #Set the model type for the detector as YOLOV3\n",
        "  detector.setModelPath('drive/MyDrive/attachments/yolo.h5') #set the model path\n",
        "  detector.loadModel() #loading the model\n",
        "  \n",
        "  #detect the objects from the image\n",
        "  detections = detector.detectObjectsFromImage(input_image = image, input_type = \"array\", output_image_path=os.path.join(current_directory , \"output.jpg\"))\n",
        "  centers = [] #Array to store the centroid of the detected\n",
        "  for eachObject in detections:\n",
        "      x1,y1,x2,y2 = eachObject[\"box_points\"] #get the bounding box coordinates of the detected object\n",
        "      cv2.rectangle(image, (x1,y1), (x2,y2), (0,0,255), 2) #draw rectangle around the detected object\n",
        "      cv2.putText(image,\"Bounding Box\",(x1+15,y1+15), 0,0.5,(0,255,0), 2)\n",
        "      cx = int((x1+x2)/2)\n",
        "      cy = int((y1+y2)/2)\n",
        "      inputCentroids = (cx,cy) #Calculating centroid of the bounding box\n",
        "      centers.append(np.array([[cx],[cy]]))\n",
        "  return centers #return the centroid of the detected object\n"
      ],
      "metadata": {
        "id": "LKmbeEK4Yy6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SINGLE OBJECT TRACKING-**\n",
        "In this part, we're initializing the KF Object with initial values for time sampling time - time taken for 1 cycle. \n",
        "we're reading the video frame by frame using CV2 video capture. while the cv2.videoCapture method returns true, pass the frame through detect_object() method and get the centroid of the detected object.\n",
        "if the centroid is detected then pass those to update function of the kalman filter. the use the predice function to predict the next state of the detected centroid.Predicts the next position of the centroid, initalised when KF object is created, converges to the real object position after first cycle This prediction works even when the object goes behind the paper. \n",
        "Finally we are using Cv2 video writer to add all the frames to a video. "
      ],
      "metadata": {
        "id": "7ipj55oNdzb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "HiSpeed= 100\n",
        "ControlSpeedVar = 30  \n",
        "    #Create KalmanFilter object KF\n",
        "    #KalmanFilter(dt, a_x, a_y, std_acc, x_std_meas, y_std_meas)\n",
        "KF = KalmanFilter(0.1, 1, 1, 1, 0.1,0.1)\n",
        "    # array to store the images to output to a video\n",
        "img_array = []\n",
        "\n",
        "VideoCap = cv2.VideoCapture('drive/MyDrive/attachments/ball.mp4')\n",
        "while(True):\n",
        " \n",
        "  ret, image = VideoCap.read()\n",
        "        # Detect object\n",
        "  if ret is False:\n",
        "      break\n",
        "  centers = object_detection(image)\n",
        "  if (len(centers) > 0):\n",
        "        # If centroids are detected then track the ball object\n",
        "            # Draw the detected circle\n",
        "    cv2.circle(image, (int(centers[0][0]), int(centers[0][1])), 10, (0, 191, 255), 2)\n",
        "    cv2.putText(image, \"Centroid\", (centers[0][0] + 15, centers[0][1] - 15), 0, 0.5, (0,191,255), 2)\n",
        "    # Update the centroid of the object\n",
        "    (x1, y1) = KF.update_object_position(centers[0])\n",
        "    #Draw a rectangle as the next estimated position of the object\n",
        "    cv2.rectangle(image, (x1 - 15, y1 - 15), (x1 + 15, y1 + 15), (255, 0, 0), 2)\n",
        "    cv2.putText(image, \"Estimated position Position\", (x1 + 15, y1), 0, 0.5, (255, 0, 0), 2)\n",
        "            # Predict the next position of the centroid, initalised when KF object is created, converges to the real object position after first cycle\n",
        "  (x, y) = KF.predict_next_position()\n",
        "            # Draw a rectangle as the predicted object position\n",
        "  cv2.rectangle(image, (x - 15, y - 15), (x + 15, y + 15), (255, 0, 0), 2)\n",
        "  cv2.putText(image, \"Predicted Position\", (x + 15, y), 0, 0.5, (255, 0, 0), 2)  \n",
        "  \n",
        "  height, width, layers = image.shape\n",
        "  size = (width,height)\n",
        "  img_array.append(image)\n",
        "\n",
        "  if cv2.waitKey(2) & 0xFF == ord('q'):\n",
        "            VideoCap.release()\n",
        "            cv2.destroyAllWindows()\n",
        "            break\n",
        "  cv2.waitKey(HiSpeed-ControlSpeedVar+1)\n",
        "\n",
        "out = cv2.VideoWriter('single_object_tracking_output.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
        "for i in range(len(img_array)):\n",
        "    out.write(img_array[i])\n",
        "out.release()"
      ],
      "metadata": {
        "id": "DWpydPDwfN3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MULTIPLE OBJECT TRACkING - Here we have 2 instances of the same object in the video. We are reading the video first and then detected the object instances using YOLOV3 pretrained model. "
      ],
      "metadata": {
        "id": "dFjGYWu3sF4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "KF1 = KalmanFilter(0.1, 1, 1, 1, 0.1,0.1)\n",
        "color = (255, 0, 0)\n",
        "thickness = 2\n",
        "current_directory = os.getcwd()\n",
        "detector = ObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath('drive/MyDrive/attachments/yolo.h5')\n",
        "detector.loadModel()\n",
        "img_array = []\n",
        "vidcap = cv2.VideoCapture('drive/MyDrive/attachments/multiple objects.avi')\n",
        "success,frame = vidcap.read()\n",
        "while success:\n",
        "    ret,image = vidcap.read()\n",
        "    \n",
        "    if ret is False:\n",
        "      break\n",
        "    height, width, layers = image.shape\n",
        "    size = (width,height)\n",
        "    detections = detector.detectObjectsFromImage(input_image = image, input_type = \"array\", output_image_path=os.path.join(current_directory , \"output.jpg\"))\n",
        "   \n",
        "    for eachObject in detections:\n",
        "      inputCentroids = np.zeros((len(detections), 2), dtype=\"int\")\n",
        "      x1,y1,x2,y2 = eachObject[\"box_points\"]\n",
        "      \n",
        "     #Calculate the centroid of the object to \n",
        "      cx = int((x1+x2)/2)\n",
        "      cy = int((y1+y2)/2)\n",
        "      inputCentroids = (cx,cy)   \n",
        "\n",
        "      cv2.rectangle(image,(x1,y1),(x2,y2), color, thickness) #bounding box of the detected object\n",
        "      cv2.putText(image, \"Bounding box\", (x1+15,y1+15), 0, 0.5, (0,255,0), 2)\n",
        "      cv2.circle(image, (cx,cy), 10, (0,0,255), thickness)\n",
        "      cv2.putText(image, \"Centroid\", (cx + 15, cy - 15), 0, 0.5, (0,255,0), 2)\n",
        "      \n",
        "       \n",
        "      img_array.append(image)\n",
        "    if cv2.waitKey(2) & 0xFF == ord('q'):\n",
        "     vidcap.release()\n",
        "     cv2.destroyAllWindows()\n",
        "     break\n",
        "out = cv2.VideoWriter('Multiple_Obj_detection_output.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
        "for i in range(len(img_array)):\n",
        "    out.write(img_array[i])\n",
        "out.release()"
      ],
      "metadata": {
        "id": "EZKL7eq-rWjX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}